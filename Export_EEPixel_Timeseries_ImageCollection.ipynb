{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Import packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pT6KulIXmSWZ"
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import ee\n",
    "import geemap\n",
    "import os\n",
    "import eeDatabase_coreMethods as eedb_cor\n",
    "import eeDatabase_collectionMethods as eedb_col\n",
    "\n",
    "# ee.Authenticate()\n",
    "ee.Initialize(project = \"climate-engine-pro\")\n",
    "\n",
    "Map = geemap.Map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4t-1HOAnF7rL"
   },
   "source": [
    "## Define Parameters and Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zQPixTuOF658"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------- Define parameters -----------------------------------------------\n",
    "\n",
    "# Define time period to export\n",
    "start_date = datetime.datetime(1980, 1, 1)\n",
    "end_date = datetime.datetime(2024, 1, 1)\n",
    "\n",
    "\n",
    "# -------------------------------- Define input Image Collection ----------------------------------------\n",
    "\n",
    "# Define input dataset\n",
    "# See dictionary below for list of input datasets\n",
    "in_ic_name = 'GridMET'\n",
    "\n",
    "# Define variable from dataset\n",
    "# See dictionary below for variables available for each dataset\n",
    "var_name = 'precip'\n",
    "\n",
    "\n",
    "# ------------------------------- Define input Feature Collection ---------------------------------------\n",
    "\n",
    "# Define input path for Feature Collection\n",
    "in_fc_path = 'projects/dri-apps/assets/blm-admin/blm-natl-admu-districtoffice-polygons'\n",
    "in_fc = ee.FeatureCollection(in_fc_path)\n",
    "\n",
    "# # Subset by geometry\n",
    "# geometry = ee.Geometry.Polygon([[[-108.4020, 38.7855], [-108.4020, 39.6080], [-109.1823, 39.6080], [-109.1823, 38.7855]]], None, False);\n",
    "# in_fc = in_fc.filterBounds(geometry)\n",
    "\n",
    "\n",
    "# ------------------------------ Define mask, if applicable --------------------------------------------\n",
    "\n",
    "# For BLM, we will apply mask to field offices, district offices, and state offices, but not to allotments\n",
    "# Apply mask for ownership, landcover, or other variables. Must be binary mask.\n",
    "mask = True\n",
    "mask_path = 'projects/dri-apps/assets/blm-admin/blm-natl-admu-sma-binary'\n",
    "\n",
    "\n",
    "# ---------------------------- Additional parameters derived from above --------------------------------\n",
    "\n",
    "# Define input Image Collection variables using dataset dictionary\n",
    "in_ic_dict = {'GridMET_Drought': {'in_ic_paths': ['GRIDMET/DROUGHT'],\n",
    "                                  'var_names': ['Long_Term_Drought_Blend', 'Short_Term_Drought_Blend'],\n",
    "                                  'var_type': 'Categorical'},\n",
    "              'GridMET': {'in_ic_paths': ['IDAHO_EPSCOR/GRIDMET'],\n",
    "                          'var_names': ['precip', 'tmmn', 'tmmx', 'eto', 'vpd', 'windspeed', 'srad'],\n",
    "                          'var_type': 'Continuous'},\n",
    "              'RAP_Cover': {'in_ic_paths': ['projects/rap-data-365417/assets/vegetation-cover-v3'],\n",
    "                            'var_names': ['AFG', 'BGR', 'LTR', 'PFG', 'SHR', 'TRE'],\n",
    "                            'var_type': 'Continuous'},\n",
    "              'RAP_Production': {'in_ic_paths': ['projects/rap-data-365417/assets/npp-partitioned-v3'],\n",
    "                                 'var_names': ['afgAGB', 'pfgAGB', 'herbaceousAGB'],\n",
    "                                 'var_type': 'Continuous'},\n",
    "              'RAP_16dProduction': {'in_ic_paths': ['projects/rap-data-365417/assets/npp-partitioned-16day-v3'],\n",
    "                                   'var_names': ['afgAGB', 'pfgAGB', 'herbaceousAGB'],\n",
    "                                   'var_type': 'Continuous'},\n",
    "              'USDM': {'in_ic_paths': ['projects/climate-engine/usdm/weekly'],\n",
    "                       'var_names': ['drought'],\n",
    "                       'var_type': 'Categorical'},\n",
    "              'MOD11_LST': {'in_ic_paths': ['MODIS/061/MOD11A2'],\n",
    "                            'var_names': ['LST_Day_1km'],\n",
    "                            'var_type': 'Continuous'},\n",
    "              'Landsat': {'in_ic_paths': ['LANDSAT/LT05/C02/T1_L2', 'LANDSAT/LE07/C02/T1_L2', 'LANDSAT/LC08/C02/T1_L2', 'LANDSAT/LC09/C02/T1_L2'],\n",
    "                          'var_names': ['NDVI'],\n",
    "                          'var_type': 'Continuous'},\n",
    "              'MOD16_ET': {'in_ic_paths': ['MODIS/006/MOD16A2'],\n",
    "                           'var_names': ['ET', 'PET'],\n",
    "                           'var_type': 'Continuous'},\n",
    "              'MTBS': {'in_ic_paths': ['projects/climate-engine-pro/assets/mtbs_mosaics_annual'],\n",
    "                       'var_names': ['Severity'],\n",
    "                       'var_type': 'Categorical'}}\n",
    "\n",
    "# Define properties for variables in dictionary\n",
    "var_dict = {'Long_Term_Drought_Blend': {'units': 'drought'},\n",
    "            'Short_Term_Drought_Blend': {'units': 'drought'},\n",
    "            'precip': {'units': 'mm'},\n",
    "            'tmmn': {'units': 'degrees C'},\n",
    "            'tmmx': {'units': 'degrees C'},\n",
    "            'eto': {'units': 'mm'},\n",
    "            'vpd': {'units': 'kPa'},\n",
    "            'windspeed': {'units': 'm/s'},\n",
    "            'srad': {'units': 'W/m^2'},\n",
    "            'AFG': {'units': '% cover'},\n",
    "            'BGR': {'units': '% cover'},\n",
    "            'LTR': {'units': '% cover'},\n",
    "            'PFG': {'units': '% cover'},\n",
    "            'SHR': {'units': '% cover'},\n",
    "            'TRE': {'units': '% cover'},\n",
    "            'afgAGB': {'units': 'lbs/acre'},\n",
    "            'pfgAGB': {'units': 'lbs/acre'},\n",
    "            'herbaceousAGB': {'units': 'lbs/acre'},\n",
    "            'drought': {'units': 'drought'},\n",
    "            'LST_Day_1km': {'units': 'degrees C'},\n",
    "            'NDVI': {'units': 'unitless'},\n",
    "            'ET': {'units': 'mm'},\n",
    "            'PET': {'units': 'mm'},\n",
    "            'Severity': {'units': 'fire severity'}}\n",
    "\n",
    "# Define land unit names\n",
    "if(in_fc_path == 'projects/dri-apps/assets/blm-admin/blm-natl-grazing-allotment-polygons'):\n",
    "    land_unit_long = 'BLM_Natl_Grazing_Allotment_Polygons'\n",
    "    land_unit_short = 'BLM_Allotments'\n",
    "    in_fc_id = 'ALLOT_ID'\n",
    "elif(in_fc_path == 'projects/dri-apps/assets/blm-admin/blm-natl-admu-fieldoffice-polygons'):\n",
    "    land_unit_long = 'BLM_Natl_FieldOffice_Polygons'\n",
    "    land_unit_short = 'BLM_FieldOffices'\n",
    "    in_fc_id = 'FO_ID'\n",
    "elif(in_fc_path == 'projects/dri-apps/assets/blm-admin/blm-natl-admu-districtoffice-polygons'):\n",
    "    land_unit_long = 'BLM_Natl_DistrictOffice_Polygons'\n",
    "    land_unit_short = 'BLM_DistrictOffices'\n",
    "    in_fc_id = 'DO_ID'\n",
    "elif(in_fc_path == 'projects/dri-apps/assets/blm-admin/blm-natl-admu-stateoffice-polygons'):\n",
    "    land_unit_long = 'BLM_Natl_StateOffice_Polygons'\n",
    "    land_unit_short = 'BLM_StateOffices'\n",
    "    in_fc_id = 'SO_ID'\n",
    "\n",
    "# Pull out additional variables needed to run exports\n",
    "in_ic_paths = in_ic_dict.get(in_ic_name).get('in_ic_paths')\n",
    "in_ic_res = ee.Number(ee.ImageCollection(in_ic_paths[0]).first().projection().nominalScale()).round().getInfo()\n",
    "var_type = in_ic_dict.get(in_ic_name).get('var_type')\n",
    "var_units = var_dict.get(var_name).get('units')\n",
    "out_path = f\"projects/climate-engine-pro/assets/blm-database/{land_unit_short.replace('_', '').lower()}-{in_ic_name.replace('_', '').lower()}-{var_name.replace('_', '').lower()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create database image collection and append time-series images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"projects/climate-engine-pro/assets/blm-database/blmdistrictoffices-gridmetdrought-shorttermdroughtblend\",\n",
      "  \"name\": \"projects/climate-engine-pro/assets/blm-database/blmdistrictoffices-gridmetdrought-shorttermdroughtblend\",\n",
      "  \"type\": \"IMAGE_COLLECTION\",\n",
      "  \"updateTime\": \"2023-06-14T15:24:09.893079Z\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"projects/climate-engine-pro/assets/blm-database/blmdistrictoffices-gridmetdrought-shorttermdroughtblend\",\n",
      "  \"name\": \"projects/climate-engine-pro/assets/blm-database/blmdistrictoffices-gridmetdrought-shorttermdroughtblend\",\n",
      "  \"type\": \"IMAGE_COLLECTION\",\n",
      "  \"updateTime\": \"2023-06-14T15:24:09.893079Z\"\n",
      "}\n",
      "Appending to Image Collection for dates 1980-01-01 00:00:00 - 1981-01-01 00:00:00\n",
      "Running  1980-01-04 23:00:00\n",
      "Running  1980-01-09 23:00:00\n",
      "Running  1980-01-14 23:00:00\n",
      "Running  1980-01-19 23:00:00\n",
      "Running  1980-01-24 23:00:00\n",
      "Running  1980-01-29 23:00:00\n",
      "Running  1980-02-03 23:00:00\n",
      "Running  1980-02-08 23:00:00\n",
      "Running  1980-02-13 23:00:00\n",
      "Running  1980-02-18 23:00:00\n",
      "Running  1980-02-23 23:00:00\n",
      "Running  1980-02-28 23:00:00\n",
      "Running  1980-03-04 23:00:00\n",
      "Running  1980-03-09 23:00:00\n",
      "Running  1980-03-14 23:00:00\n",
      "Running  1980-03-19 23:00:00\n",
      "Running  1980-03-24 23:00:00\n",
      "Running  1980-03-29 23:00:00\n",
      "Running  1980-04-03 23:00:00\n",
      "Running  1980-04-08 23:00:00\n",
      "Running  1980-04-13 23:00:00\n",
      "Running  1980-04-18 23:00:00\n",
      "Running  1980-04-23 23:00:00\n",
      "Running  1980-04-29 00:00:00\n",
      "Running  1980-05-04 00:00:00\n",
      "Running  1980-05-09 00:00:00\n",
      "Running  1980-05-14 00:00:00\n",
      "Running  1980-05-19 00:00:00\n",
      "Running  1980-05-24 00:00:00\n",
      "Running  1980-05-29 00:00:00\n",
      "Running  1980-06-03 00:00:00\n",
      "Running  1980-06-08 00:00:00\n",
      "Running  1980-06-13 00:00:00\n",
      "Running  1980-06-18 00:00:00\n",
      "Running  1980-06-23 00:00:00\n",
      "Running  1980-06-28 00:00:00\n",
      "Running  1980-07-03 00:00:00\n",
      "Running  1980-07-08 00:00:00\n",
      "Running  1980-07-13 00:00:00\n",
      "Running  1980-07-18 00:00:00\n",
      "Running  1980-07-23 00:00:00\n",
      "Running  1980-07-28 00:00:00\n",
      "Running  1980-08-02 00:00:00\n",
      "Running  1980-08-07 00:00:00\n",
      "Running  1980-08-12 00:00:00\n",
      "Running  1980-08-17 00:00:00\n",
      "Running  1980-08-22 00:00:00\n",
      "Running  1980-08-27 00:00:00\n",
      "Running  1980-09-01 00:00:00\n",
      "Running  1980-09-06 00:00:00\n",
      "Running  1980-09-11 00:00:00\n",
      "Running  1980-09-16 00:00:00\n",
      "Running  1980-09-21 00:00:00\n",
      "Running  1980-09-26 00:00:00\n",
      "Running  1980-10-01 00:00:00\n",
      "Running  1980-10-06 00:00:00\n",
      "Running  1980-10-11 00:00:00\n",
      "Running  1980-10-16 00:00:00\n",
      "Running  1980-10-21 00:00:00\n",
      "Running  1980-10-26 00:00:00\n",
      "Running  1980-10-30 23:00:00\n",
      "Running  1980-11-04 23:00:00\n",
      "Running  1980-11-09 23:00:00\n",
      "Running  1980-11-14 23:00:00\n",
      "Running  1980-11-19 23:00:00\n",
      "Running  1980-11-24 23:00:00\n",
      "Running  1980-11-29 23:00:00\n",
      "Running  1980-12-04 23:00:00\n",
      "Running  1980-12-09 23:00:00\n",
      "Running  1980-12-14 23:00:00\n",
      "Running  1980-12-19 23:00:00\n",
      "Running  1980-12-24 23:00:00\n",
      "Running  1980-12-29 23:00:00\n"
     ]
    }
   ],
   "source": [
    "# If there is no Image Collection asset at the out_path create one and export ID image\n",
    "if os.system(f\"earthengine asset info {out_path}\") == 256:\n",
    "\n",
    "    print(\"Initializing Image Collection by creating EE asset and exporting ID image\")\n",
    "    \n",
    "    # Create dictionary of properties\n",
    "    properties = {'system:index': '0_id', 'land_unit_long': land_unit_long, 'land_unit_short': land_unit_short, 'in_fc_path': in_fc_path, \n",
    "                  'in_fc_id': in_fc_id, 'in_ic_paths': in_ic_paths[0], 'in_ic_name': in_ic_name, 'in_ic_res': in_ic_res, 'var_type': var_type, \n",
    "                  'var_name': var_name, 'var_units': var_units, 'mask': mask}\n",
    "    if mask == True:\n",
    "            properties['mask_path'] = mask_path\n",
    "    elif mask == False:\n",
    "            properties['mask_path'] = 'None'\n",
    "    \n",
    "    # Apply ID image function to input feature collection\n",
    "    out_list = eedb_cor.generate_id_img(in_fc = in_fc, in_fc_id = in_fc_id)\n",
    "    out_i = ee.Image(out_list.get(0))\n",
    "    out_fc = ee.FeatureCollection(out_list.get(1))\n",
    "    \n",
    "    # Generate empty Image Collection asset to append images\n",
    "    os.system(f\"earthengine create collection {out_path}\")\n",
    "    \n",
    "    # Export ID image to new Image Collection\n",
    "    task = ee.batch.Export.image.toAsset(\n",
    "        image = out_i.set(properties),\n",
    "        description = f\"initialize - {land_unit_short.replace('_', '').lower()} {in_ic_name.replace('_', '').lower()} {var_name.replace('_', '').lower()} - id\",\n",
    "        assetId = out_path + '/0_id',\n",
    "        region = out_fc.geometry().buffer(20),\n",
    "        scale = 22.264,\n",
    "        maxPixels = 1e13)\n",
    "    task.start()\n",
    "\n",
    "    \n",
    "# If there is an Image Collection asset at the out_path export time-series images\n",
    "elif os.system(f\"earthengine asset info {out_path}\") == 0:\n",
    "\n",
    "    print(f\"Appending to Image Collection for dates {start_date} - {end_date}\")\n",
    "\n",
    "\n",
    "    # ----- Preprocess input Image Collection based on path for each date -----\n",
    "\n",
    "    dates = eedb_col.get_collection_dates(in_ic_paths, start_date, end_date)\n",
    "\n",
    "    for date in dates:\n",
    "        print(\"Running \", datetime.datetime.fromtimestamp(date/1000.0))\n",
    "        \n",
    "        date_ymd = datetime.datetime.fromtimestamp(date/1000.0).strftime('%Y%m%d')\n",
    "\n",
    "        if in_ic_paths == ['GRIDMET/DROUGHT']:\n",
    "\n",
    "            # Run function to pre-process the GridMET drought data\n",
    "            in_i = eedb_col.preprocess_gm_drought(in_ic_paths, var_name, date)\n",
    "  \n",
    "        elif in_ic_paths == ['IDAHO_EPSCOR/GRIDMET']:\n",
    "\n",
    "            # Run function to pre-process the GridMET data\n",
    "            in_i = eedb_col.preprocess_gm(in_ic_paths, var_name, date)\n",
    "\n",
    "        elif in_ic_paths == ['projects/rap-data-365417/assets/vegetation-cover-v3'] or in_ic_paths == ['projects/rap-data-365417/assets/npp-partitioned-v3'] or in_ic_paths == ['projects/rap-data-365417/assets/npp-partitioned-16day-v3']:\n",
    "\n",
    "            # Run function to pre-process the RAP data\n",
    "            in_i = eedb_col.preprocess_rap(in_ic_paths, var_name, date)\n",
    "\n",
    "        elif in_ic_paths == ['projects/climate-engine/usdm/weekly']:\n",
    "\n",
    "            # Run function to pre-process the USDM data\n",
    "            in_i = eedb_col.preprocess_usdm(in_ic_paths, var_name, date)\n",
    "\n",
    "        elif in_ic_paths == ['MODIS/061/MOD11A2']:\n",
    "\n",
    "            # Run function to pre-process the MODIS LST data\n",
    "            in_i = eedb_col.preprocess_modlst(in_ic_paths, var_name, date)\n",
    "\n",
    "        elif in_ic_paths == ['LANDSAT/LT05/C02/T1_L2', 'LANDSAT/LE07/C02/T1_L2', 'LANDSAT/LC08/C02/T1_L2', 'LANDSAT/LC09/C02/T1_L2']:\n",
    "\n",
    "            # Run function to pre-process the Landsat SR NDVI data\n",
    "            in_i = eedb_col.preprocess_lsndvi(in_ic_paths, var_name, date, in_fc)\n",
    "\n",
    "        elif in_ic_paths == ['MODIS/006/MOD16A2']:\n",
    "\n",
    "            # Run function to pre-process the MODIS ET data\n",
    "            in_i = eedb_col.preprocess_modet(in_ic_paths, var_name, date)\n",
    "\n",
    "        elif in_ic_paths == ['projects/climate-engine-pro/assets/mtbs_mosaics_annual']:\n",
    "\n",
    "            # Run function to pre-process the MTBS data\n",
    "            in_i = eedb_col.preprocess_mtbs(in_ic_paths, var_name, date)\n",
    "\n",
    "\n",
    "        # ---------------------------- Apply functions to output image ---------------------------------\n",
    "\n",
    "        # Conditionally apply mask to images\n",
    "        if mask == True:\n",
    "\n",
    "            # Select date band for single date\n",
    "            in_i = in_i.updateMask(ee.Image(mask_path))\n",
    "\n",
    "        elif mask == False:\n",
    "\n",
    "            # Select date band for single date\n",
    "            in_i = in_i\n",
    "\n",
    "        # Create dictionary of properties        \n",
    "        properties = {'system:index': date_ymd, 'system:time_start': date, 'land_unit_long': land_unit_long, 'land_unit_short': land_unit_short, 'in_fc_path': in_fc_path,\\\n",
    "                      'in_fc_id': in_fc_id, 'in_ic_paths': in_ic_paths[0], 'in_ic_name': in_ic_name, 'in_ic_res': in_ic_res, 'var_type': var_type,\\\n",
    "                      'var_name': var_name, 'var_units': var_units, 'mask': mask}\n",
    "        \n",
    "        # Conditionally add mask path to properties\n",
    "        if mask == True:\n",
    "            properties['mask_path'] = mask_path\n",
    "        elif mask == False:\n",
    "            properties['mask_path'] = 'None'\n",
    "\n",
    "        if var_type == 'Continuous':\n",
    "\n",
    "            # Run function to get time-series statistics for input feature collection\n",
    "            out_fc = eedb_cor.img_to_pts_continuous(in_i, in_fc)\n",
    "\n",
    "            # Convert centroid time-series to image collection time-series\n",
    "            out_i = eedb_cor.pts_to_img_continuous(in_fc = out_fc)\n",
    "\n",
    "        elif var_type == 'Categorical':\n",
    "\n",
    "            # Run function to get time-series statistics for input feature collection for continuous variables\n",
    "            out_fc = eedb_cor.img_to_pts_categorical(in_i, in_fc, in_ic_name = in_ic_name)\n",
    "\n",
    "            # Convert centroid time-series to image collection time-series\n",
    "            out_i = eedb_cor.pts_to_img_categorical(in_fc = out_fc, in_ic_name = in_ic_name)\n",
    "\n",
    "        # Create out region for export\n",
    "        out_region = out_fc.geometry().buffer(20)\n",
    "\n",
    "        # Export the image\n",
    "        eedb_cor.export_img(out_i = out_i, out_region = out_region, out_path = out_path, out_id = date_ymd, properties = properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check completeness of image collections and re-run any images that are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[315900000000, 316332000000, 316764000000, 317196000000, 317628000000, 318060000000, 318492000000, 318924000000, 319356000000, 319788000000, 320220000000, 320652000000, 321084000000, 321516000000, 321948000000, 322380000000, 322812000000, 323244000000, 323676000000, 324108000000, 324540000000, 324972000000, 325404000000, 325836000000, 326268000000, 326700000000, 327132000000, 327564000000, 327996000000, 328428000000, 328860000000, 329292000000, 329724000000, 330156000000, 330588000000, 331020000000, 331452000000, 331884000000, 332316000000, 332748000000, 333180000000, 333612000000, 334044000000, 334476000000, 334908000000, 335340000000, 335772000000, 336204000000, 336636000000, 337068000000, 337500000000, 337932000000, 338364000000, 338796000000, 339228000000, 339660000000, 340092000000, 340524000000, 340956000000, 341388000000, 341820000000, 342252000000, 342684000000, 343116000000, 343548000000, 343980000000, 344412000000, 344844000000, 345276000000, 345708000000, 346140000000, 346572000000, 347004000000]\n",
      "[315900000000, 316332000000, 316764000000, 317196000000, 317628000000, 318060000000, 318492000000, 318924000000, 319356000000, 319788000000, 320220000000, 320652000000, 321084000000, 321516000000, 321948000000, 322380000000, 322812000000, 323244000000, 323676000000, 324108000000, 324540000000, 324972000000, 325404000000, 325836000000, 326268000000, 326700000000, 327132000000, 327564000000, 327996000000, 328428000000, 328860000000, 329292000000, 329724000000, 330156000000, 330588000000, 331020000000, 331452000000, 331884000000, 332316000000, 332748000000, 333180000000, 333612000000, 334044000000, 334476000000, 334908000000, 335340000000, 335772000000, 336204000000, 336636000000, 337068000000, 337500000000, 337932000000, 338364000000, 338796000000, 339228000000, 339660000000, 340092000000, 340524000000, 340956000000, 341388000000, 341820000000, 342252000000, 342684000000, 343116000000, 343548000000, 343980000000, 344412000000, 344844000000, 345276000000, 345708000000, 346140000000, 346572000000, 347004000000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of all dates\n",
    "all_dates = eedb_col.get_collection_dates(in_ic_paths, start_date, end_date)\n",
    "\n",
    "# Get list of dates from collection\n",
    "coll_dates = ee.ImageCollection(out_path).aggregate_array('system:time_start').distinct().getInfo()\n",
    "\n",
    "# Get list of dates missing from collection\n",
    "set(all_dates) - set(coll_dates)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Export_BLM_TimeSeries_ImageCollection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
