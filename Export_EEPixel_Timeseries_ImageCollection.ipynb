{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To dos\n",
    "1) Set up script to first initialize database image collection (create image collection and write ID image) and then to loop over the dates in the input image collection\n",
    "2) Add additional reducers  \n",
    "- For continuous datasets - 5th, 25th, 50th, 75th, and 95th percentile, mean \n",
    "- For categorical datasets - Histogram\n",
    "2) Set up to handle reducers continuous and/or categorical datasets \n",
    "3) Add checks whether image asset already exists  \n",
    "4) Handle NAs\n",
    "5) Set export parameters as properties (resolution, continuous vs. categorical, unit reduced)  \n",
    "6) Right now the exports are run over a specified period of time (one month, one year, etc. — iterated), but may want to assess applying to one image at a time\n",
    "7) Test with RAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTeLmxy6lVf0",
    "outputId": "9ef1ee0e-56a4-4929-f7e5-34fe9ae610d7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=MSkIyBFFewK5SZytqapo3dnGLXfI0k2QA9mg2h13DTs&tc=CfbmA2mtM4eCd3GUdrljbHHpoqAFgSUVm9czwuwgbis&cc=84AdTNRnV5m0OZpWibhdUZSQ27Au5TE2g77F9eMi5jQ>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=MSkIyBFFewK5SZytqapo3dnGLXfI0k2QA9mg2h13DTs&tc=CfbmA2mtM4eCd3GUdrljbHHpoqAFgSUVm9czwuwgbis&cc=84AdTNRnV5m0OZpWibhdUZSQ27Au5TE2g77F9eMi5jQ</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 4/1AWtgzh6AIKjDjeVn9Zy5YuIG6E9cczESz9_4ceQDqNChGAUhPtky9wKwOn0\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "pT6KulIXmSWZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tqsVXzlDc6w1",
    "outputId": "5e4051c2-b31e-40bd-ee13-0950739171bd"
   },
   "outputs": [],
   "source": [
    "# !pip install geemap\n",
    "import ee\n",
    "import geemap\n",
    "Map = geemap.Map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4t-1HOAnF7rL"
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "zQPixTuOF658"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------- Define parameters -----------------------------------------------\n",
    "\n",
    "# Define time period to export\n",
    "daysToExport = 30\n",
    "startDate = datetime.datetime(2022, 1, 1)\n",
    "\n",
    "# Define whether to initialize new image collection or append to existing image collection\n",
    "process = 'initialize' \n",
    "\n",
    "\n",
    "# -------------------------------- Define input Image Collection ----------------------------------------\n",
    "\n",
    "# Define input Image Collection\n",
    "in_ic = ee.ImageCollection(\"GRIDMET/DROUGHT\").filterDate(startDate, startDate + timedelta(days = daysToExport))\n",
    "\n",
    "# Define variable to generate database table for\n",
    "var_name = 'long_term_blend'\n",
    "in_var_type = 'continuous'\n",
    "\n",
    "# Other datasets\n",
    "# gm_blends = ee.ImageCollection(\"GRIDMET/DROUGHT\")\n",
    "# rap_npp = ee.ImageCollection(\"projects/rangeland-analysis-platform/npp-partitioned-v3\")\n",
    "# rap_cov = ee.ImageCollection(\"projects/rangeland-analysis-platform/vegetation-cover-v3\")\n",
    "# gm_mat = ee.ImageCollection(\"projects/rangeland-analysis-platform/gridmet-MAT\")\n",
    "\n",
    "\n",
    "# ------------------------------- Define input Feature Collection ---------------------------------------\n",
    "\n",
    "# in_fc = ee.FeatureCollection('projects/dri-apps/assets/blm-admin/BLM_Natl_Grazing_Allotment_Polygons')\n",
    "in_fc = ee.FeatureCollection('projects/dri-apps/assets/BLM_Natl_Grazing_Allotment_Polygons_Simplified_clean')\n",
    "\n",
    "# # Subset by geometry\n",
    "# geometry = ee.Geometry.Polygon([[[-108.4020, 38.7855], [-108.4020, 39.6080], [-109.1823, 39.6080], [-109.1823, 38.7855]]], None, False);\n",
    "# in_fc = in_fc.filterBounds(geometry)\n",
    "# # Specify ID property\n",
    "# in_fc_id = \"ALLOT_ID\"\n",
    "\n",
    "# Use full Feature Collection\n",
    "in_fc = in_fc\n",
    "# Specify ID property\n",
    "in_fc_id = \"ALLOT_ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpqLcwg5maQb"
   },
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K59x-CS-Fwm-"
   },
   "source": [
    "### Calculate GridMET drought blends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "OYGJjcFfmU44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20220105', '20220110', '20220115', '20220120', '20220125', '20220130']\n"
     ]
    }
   ],
   "source": [
    "# Define property list\n",
    "property_list = [\"system:index\", \"system:time_start\"]\n",
    "\n",
    "# Function to calculate short-term and long-term blends\n",
    "def preprocess_gm_drought(img):\n",
    "\n",
    "  # Define preliminary variables for short-term blend calculation\n",
    "  stb_variable = \"short_term_blend\"\n",
    "  stb_pdsi_img = img.select(\"pdsi\")\n",
    "  stb_z_img = img.select(\"z\")\n",
    "  stb_spi90d_img = img.select(\"spi90d\")\n",
    "  stb_spi30d_img = img.select(\"spi30d\")\n",
    "\n",
    "  # Define weights for short-term blend calculation\n",
    "  stb_pdsi_coef = 0.2\n",
    "  stb_z_coef = 0.35\n",
    "  stb_spi90d_coef = 0.25\n",
    "  stb_spi30d_coef = 0.2\n",
    "\n",
    "  # Calculate short-term blend\n",
    "  stblend = stb_pdsi_img.expression(\n",
    "      \"b() * pdsi_coef / 2 + spi90d * spi90d_coef + spi30d * spi30d_coef + z * z_coef / 2\",{\n",
    "          \"spi90d\": stb_spi90d_img, \n",
    "          \"spi30d\": stb_spi30d_img, \n",
    "          \"z\": stb_z_img, \n",
    "          \"pdsi_coef\": stb_pdsi_coef,\n",
    "          \"spi90d_coef\": stb_spi90d_coef, \n",
    "          \"spi30d_coef\": stb_spi30d_coef, \n",
    "          \"z_coef\": stb_z_coef})\n",
    "\n",
    "  # Define preliminary variables for long-term blend calculation\n",
    "  ltb_variable = \"long_term_blend\"\n",
    "  ltb_pdsi_img = img.select(\"pdsi\")\n",
    "  ltb_spi180d_img = img.select(\"spi180d\")\n",
    "  ltb_spi1y_img = img.select(\"spi1y\")\n",
    "  ltb_spi2y_img = img.select(\"spi2y\")\n",
    "  ltb_spi5y_img = img.select(\"spi5y\")\n",
    "\n",
    "  # Define weights for long-term blend calculation\n",
    "  ltb_pdsi_coef = 0.35\n",
    "  ltb_spi180d_coef = 0.15\n",
    "  ltb_spi1y_coef = 0.2\n",
    "  ltb_spi2y_coef = 0.2\n",
    "  ltb_spi5y_coef = 0.1\n",
    "\n",
    "  # Calculate short-term blend\n",
    "  ltblend = ltb_pdsi_img.expression(\n",
    "      \"b() * pdsi_coef / 2 + spi180d* spi180d_coef + spi1y * spi1y_coef + spi2y * spi2y_coef + spi5y * spi5y_coef\",{\n",
    "          \"spi180d\": ltb_spi180d_img, \n",
    "          \"spi1y\": ltb_spi1y_img, \n",
    "          \"spi2y\": ltb_spi2y_img, \n",
    "          \"spi5y\": ltb_spi5y_img,\n",
    "          \"spi180d_coef\": ltb_spi180d_coef, \n",
    "          \"spi1y_coef\": ltb_spi1y_coef, \n",
    "          \"spi2y_coef\": ltb_spi2y_coef,\n",
    "          \"spi5y_coef\": ltb_spi5y_coef, \n",
    "          \"pdsi_coef\": ltb_pdsi_coef})\n",
    "  \n",
    "  return ltblend.addBands(stblend).select([0,1], [ltb_variable, stb_variable]).copyProperties(img, property_list)\n",
    "\n",
    "# Map function to calculate drought blends over the subset years, convert to monthly median images, and convert to multi-band image\n",
    "# Filter for dates without NAs for the long term blend\n",
    "in_ic = in_ic.filterDate('1985-01-01', str(date.today()))\\\n",
    "                 .map(preprocess_gm_drought)\n",
    "\n",
    "# Convert Image Collection to multi-band image\n",
    "in_i = in_ic.toBands()\n",
    "\n",
    "# Select variable to serve as input\n",
    "in_i = in_i.select(['[0-9]{8}_' + var_name])\n",
    "\n",
    "# Bandnames must be an eight digit character string 'YYYYMMDD'. Annual data will be 'YYYY0101'.\n",
    "def replace_name(name):\n",
    "  return ee.String(name).replace(var_name, '').replace('_', '')\n",
    "\n",
    "# Finish cleaning input image\n",
    "in_i = in_i.rename(in_i.bandNames().map(replace_name))\n",
    "print(in_i.bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-br62MPmlp8"
   },
   "source": [
    "## Reduce regions to time-series centroid Feature Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "rQ6wyBsa1uWS"
   },
   "outputs": [],
   "source": [
    "# Function to return feature time-series as centroid feature collection for continuous variabless\n",
    "def imgs_to_pts_continuous(img):\n",
    "    \n",
    "    # Cast input image to ee.Image\n",
    "    img = ee.Image(img)\n",
    "    \n",
    "    # Get resolution of the image\n",
    "    res = img.select(0).projection().nominalScale()\n",
    "    \n",
    "    # Run reduce regions for allotments\n",
    "    img_rr = img.reduceRegions(collection = in_fc,\\\n",
    "                                 reducer = ee.Reducer.percentile([5, 25, 50, 75, 95]),\\\n",
    "                                 scale = res,\\\n",
    "                                 tileScale = 16)\n",
    "    \n",
    "    # Function to clean up property names\n",
    "    def clean_f(f):\n",
    "        \n",
    "        # Get ID for the input feature\n",
    "        f_id = f.get(in_fc_id)\n",
    "        \n",
    "        # Rename ID for later sorting\n",
    "        f = f.set(\"0_id\", ee.Number.parse(f_id))\n",
    "        \n",
    "        # Select ID band and time-series bands and convert to centroids\n",
    "        return(ee.Feature(f.select(['0_id', '[0-9]{8}.*']))\\\n",
    "                       .centroid())\n",
    "    \n",
    "    # Apply function to clean up property names\n",
    "    img_rr = img_rr.map(clean_f)\n",
    "    \n",
    "    # Get list of RR features\n",
    "    img_rr_list = img_rr.toList(img_rr.size())\n",
    "    \n",
    "    # Get size of RR features\n",
    "    img_rr_size = img_rr_list.size()\n",
    "    \n",
    "    # Function to create feature collection next to equator\n",
    "    def pts_to_equator(i):\n",
    "        \n",
    "        # Cast number to EE number\n",
    "        i = ee.Number(i)\n",
    "        \n",
    "        # Get properties\n",
    "        properties = ee.Feature(img_rr_list.get(i)).toDictionary()\n",
    "        \n",
    "        # Create geometry at equator\n",
    "        geom = ee.Geometry.Point([i.multiply(0.0002), 0.0002])\n",
    "        \n",
    "        # Return object with properties\n",
    "        return(ee.Feature(geom).set(properties))\n",
    "    \n",
    "    # Create equator feature collection\n",
    "    proxy_fc = ee.FeatureCollection(ee.List.sequence(0, img_rr_size.subtract(1), 1).map(pts_to_equator))\n",
    "    \n",
    "    return(proxy_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KnuYNrSaI3mz",
    "outputId": "63f68e2a-22a9-439b-922f-4ee5f977639e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_id', '20220105_p25', '20220105_p5', '20220105_p50', '20220105_p75', '20220105_p95', '20220110_p25', '20220110_p5', '20220110_p50', '20220110_p75', '20220110_p95', '20220115_p25', '20220115_p5', '20220115_p50', '20220115_p75', '20220115_p95', 'system:index']\n",
      "21591\n"
     ]
    }
   ],
   "source": [
    "# Run function to get time-series statistics for input feature collection for continuous variables\n",
    "rr_fc = imgs_to_pts_continuous(in_i)\n",
    "print(rr_fc.first().propertyNames().sort().getInfo())\n",
    "print(rr_fc.size().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1mJDvHuKI8o"
   },
   "source": [
    "## Convert centroid time-series to Image Collection time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate series image collection from feature collections\n",
    "def pts_to_ics_continuous(in_fc):\n",
    "\n",
    "    # Get list of property names\n",
    "    def slice_strs(str):\n",
    "        return(ee.String(str).slice(0,8))\n",
    "\n",
    "    # Get list of unique dates   \n",
    "    fc_dates = in_fc.first().propertyNames().sort().remove(\"system:index\").map(slice_strs).distinct() \n",
    "\n",
    "    # Generate time-series feature collection\n",
    "    def generate_date_fc(date):\n",
    "        date = ee.String(date)\n",
    "\n",
    "        # Select the properties for the date\n",
    "        def filter_f_properties(f):\n",
    "            # Select properties for the date\n",
    "            f_sub = ee.Feature(f).select([date.cat('.*')])\n",
    "\n",
    "            # Function to remove date from property names\n",
    "            def clean_property_names(prop):\n",
    "\n",
    "                return(ee.String(prop).replace(date.cat('_'), '').replace('0_id', 'id'))\n",
    "\n",
    "            # Remove dates from property names\n",
    "            f_sub = ee.Feature(f_sub).select(f_sub.propertyNames(), f_sub.propertyNames().map(clean_property_names))\n",
    "            return(ee.Feature(f_sub))\n",
    "\n",
    "        # Apply function to select the Feature properties for the date and add new properties for the output Feature Collection\n",
    "        f_sub_clean = ee.FeatureCollection(in_fc.map(filter_f_properties)).set('system:index', date).set('f_id', date)\n",
    "\n",
    "        return(f_sub_clean)\n",
    "\n",
    "    # Apply function to produce time-series feature collection\n",
    "    fc_dates = fc_dates.map(generate_date_fc)\n",
    "\n",
    "    # Convert dates Feature Collection to Image Collection\n",
    "    def fcs_to_ic(fc):\n",
    "        # Cast to FeatureCollections\n",
    "        fc = ee.FeatureCollection(fc)\n",
    "\n",
    "        # Get list of properties to iterate over for creating multiband image for each date\n",
    "        props = fc.first().propertyNames().remove('system:index')\n",
    "\n",
    "        # Function to generate image from stats stored in Feature Collection property\n",
    "        def generate_stat_image(prop):\n",
    "            img = fc.reduceToImage(properties = [prop], reducer = ee.Reducer.sum()).rename([prop])\n",
    "            return(img)\n",
    "\n",
    "        # Generate multi-band stats image\n",
    "        img_mb = ee.ImageCollection(props.map(generate_stat_image)).toBands().rename(props).set(\"system:index\", fc.get('f_id')).set(\"var_name\", var_name)\n",
    "\n",
    "        return(img_mb)\n",
    "    \n",
    "    ic_from_fcs = fc_dates.map(fcs_to_ic)\n",
    "    \n",
    "    return(ic_from_fcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "uti_bBynLbmC"
   },
   "outputs": [],
   "source": [
    "# Convert centroid time-series to image collection time-series\n",
    "rr_ic = ee.ImageCollection(pts_to_ics_continuous(rr_fc))\n",
    "# print(ee.Image(rr_ic.toList(10).get(1)).bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "collapsed": true,
    "id": "dX394q1Admjl",
    "outputId": "83786647-d793-4ad5-be7e-2dabcfe2f687"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fc609460464c54b20257f9fa76242d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Create export geometry\n",
    "# geometry = rr_fc.geometry().bounds().buffer(1000)\n",
    "\n",
    "# Map = geemap.Map()\n",
    "# Map.addLayer(ee.Image(rr_ic.first()))\n",
    "# Map.addLayer(geometry)\n",
    "# Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lL2M0PMJTN7n"
   },
   "source": [
    "## Export Images to Image Collection Asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Uabmqw-Tpps",
    "outputId": "66499f5e-60bd-4dba-fd62-72526131d436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gridmet-long-term-blend\n",
      "Asset projects/dri-apps/assets/blm-database/gridmet-long-term-blend already exists.\n"
     ]
    }
   ],
   "source": [
    "# -------- Define export parameters -----------\n",
    "# Define asset to export\n",
    "out_ic = rr_ic\n",
    "out_ic_str = 'gridmet-' + var_name.replace('_', '-')\n",
    "print(out_ic_str)\n",
    "\n",
    "# Parse Image Collection ID\n",
    "ic_id = f\"projects/dri-apps/assets/blm-database/{out_ic_str}\"\n",
    "\n",
    "# Generate empty Image Collection asset to append images\n",
    "os.system(f\"earthengine create collection {ic_id}\")\n",
    "\n",
    "# -------- Get list of image IDs -----------\n",
    "# Get image ID\n",
    "# Return from EE IC\n",
    "img_ids = out_ic.aggregate_array('system:index').getInfo()\n",
    "# print(img_ids)\n",
    "\n",
    "# -------- Create export tasks ---------\n",
    "# Create export geometry\n",
    "geometry = rr_fc.geometry().bounds().buffer(300)\n",
    "\n",
    "# Loop over IDs to generate export tasks\n",
    "for i, img_id in enumerate(img_ids):\n",
    "    img = ee.Image(out_ic.filter(ee.Filter.eq('system:index', img_id)).first())\n",
    "    task = ee.batch.Export.image.toAsset(\n",
    "        image = ee.Image(img),\n",
    "        description = img_id,\n",
    "        assetId = ic_id + \"/\" + img_id,\n",
    "        scale = 22.264,\n",
    "        region = geometry,\n",
    "        maxPixels = 1e13\n",
    "    )\n",
    "    \n",
    "    task.start()\n",
    "    print(img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "!earthengine rm --recursive projects/ce-datasets/assets/blm-allotment-ics/blm-rap-cover-afg"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Export_BLM_TimeSeries_ImageCollection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
