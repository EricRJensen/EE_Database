{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To dos  \n",
    "1) Handle custom bin widths of histograms for categorical datasets  \n",
    "2) Generate preprocessing scripts for other datasets  \n",
    "3) Make sure datetimes are set as system:timestart for filtering  \n",
    "4) Incorporate notes: https://docs.google.com/document/d/1WMLKJiXq87lZbjD6lXSeodNaR30Oh1TTlfnikyNvuvM/edit\n",
    "    Check that changes are working okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pT6KulIXmSWZ"
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import ee\n",
    "import geemap\n",
    "import os\n",
    "import eeDatabase_coreMethods as eedb_cor\n",
    "import eeDatabase_collectionMethods as eedb_col\n",
    "import ee\n",
    "\n",
    "# ee.Authenticate()\n",
    "ee.Initialize(project = \"dri-apps\")\n",
    "\n",
    "Map = geemap.Map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4t-1HOAnF7rL"
   },
   "source": [
    "## Define Parameters and Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zQPixTuOF658"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------- Define parameters -----------------------------------------------\n",
    "\n",
    "# Define time period to export\n",
    "start_date = datetime.datetime(2022, 1, 1)\n",
    "end_date = datetime.datetime(2022, 2, 1)\n",
    "\n",
    "\n",
    "# -------------------------------- Define input Image Collection ----------------------------------------\n",
    "\n",
    "# Define input dataset\n",
    "# See dictionary below for list of input datasets\n",
    "in_ic_name = 'USDM'\n",
    "\n",
    "# Define variable from dataset\n",
    "# See dictionary below for variables available for each dataset\n",
    "var_name = 'drought'\n",
    "\n",
    "\n",
    "# ------------------------------- Define input Feature Collection ---------------------------------------\n",
    "\n",
    "# Define input path for Feature Collection\n",
    "in_fc_path = 'projects/dri-apps/assets/blm-admin/blm-natl-grazing-allotment-polygons-simplified-clean'\n",
    "in_fc = ee.FeatureCollection(in_fc_path)\n",
    "\n",
    "# Specify ID property\n",
    "in_fc_id = \"ALLOT_ID\"\n",
    "\n",
    "# # Subset by geometry\n",
    "# geometry = ee.Geometry.Polygon([[[-108.4020, 38.7855], [-108.4020, 39.6080], [-109.1823, 39.6080], [-109.1823, 38.7855]]], None, False);\n",
    "# in_fc = in_fc.filterBounds(geometry)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------- Additional parameters derived from above --------------------------------\n",
    "\n",
    "# Define input Image Collection variables using dataset dictionary\n",
    "in_ic_dict = {'GridMET_Drought': {'in_ic_paths': ['GRIDMET/DROUGHT'],\n",
    "                                  'var_names': ['Long_Term_Drought_Blend', 'Short_Term_Drought_Blend'],\n",
    "                                  'var_type': 'Categorical'},\n",
    "              'GridMET': {'in_ic_paths': ['IDAHO_EPSCOR/GRIDMET'],\n",
    "                                  'var_names': ['precip', 'tmmn', 'tmmx', 'eto', 'vpd'],\n",
    "                                  'var_type': 'Continuous'},\n",
    "              'RAP_Cover': {'in_ic_paths': ['projects/rap-data-365417/assets/vegetation-cover-v3'],\n",
    "                           'var_names': ['AFG', 'BGR', 'LTR', 'PFG', 'SHR', 'TRE'],\n",
    "                           'var_type': 'Continuous'},\n",
    "              'RAP_Production': {'in_ic_paths': ['projects/rap-data-365417/assets/npp-partitioned-v3'],\n",
    "                                'var_names': ['afgAGB', 'pfgAGB', 'herbaceousAGB'],\n",
    "                                'var_type': 'Continuous'},\n",
    "              'RAP16_Production': {'in_ic_paths': ['projects/rap-data-365417/assets/npp-partitioned-16day-v3'],\n",
    "                                'var_names': ['afgAGB', 'pfgAGB', 'herbaceousAGB'],\n",
    "                                'var_type': 'Continuous'},\n",
    "              'USDM': {'in_ic_paths': ['projects/climate-engine/usdm/weekly'],\n",
    "                      'var_names': ['drought'],\n",
    "                      'var_type': 'Categorical'},\n",
    "              'MOD11_LST': {'in_ic_paths': ['MODIS/061/MOD11A2'],\n",
    "                           'var_names': ['LST_Day_1km'],\n",
    "                           'var_type': 'Continuous'},\n",
    "              'LS_NDVI': {'in_ic_paths': ['LANDSAT/LT05/C02/T1_L2', 'LANDSAT/LE07/C02/T1_L2', 'LANDSAT/LC08/C02/T1_L2', 'LANDSAT/LC09/C02/T1_L2'],\n",
    "                           'var_names': ['NDVI'],\n",
    "                           'var_type': 'Continuous'},\n",
    "              'MOD16_ET': {'in_ic_paths': ['MODIS/061/MOD16A2'],\n",
    "                          'var_names': ['ET', 'PET'],\n",
    "                          'var_type': 'Continuous'}}\n",
    "\n",
    "# Define properties for variables in dictionary\n",
    "var_dict = {'Long_Term_Drought_Blend': {'units': 'classification'},\n",
    "            'Short_Term_Drought_Blend': {'units': 'classification'},\n",
    "            'precip': {'units': 'mm'},\n",
    "            'tmmn': {'units': 'degrees C'},\n",
    "            'tmmx': {'units': 'degrees C'},\n",
    "            'eto': {'units': 'mm'},\n",
    "            'vpd': {'units': 'kPa'},\n",
    "            'AFG': {'units': '% cover'},\n",
    "            'BGR': {'units': '% cover'},\n",
    "            'LTR': {'units': '% cover'},\n",
    "            'PFG': {'units': '% cover'},\n",
    "            'SHR': {'units': '% cover'},\n",
    "            'TRE': {'units': '% cover'},\n",
    "            'afgAGB': {'units': 'lbs/acre'},\n",
    "            'pfgAGB': {'units': 'lbs/acre'},\n",
    "            'herbaceousAGB': {'units': 'lbs/acre'},\n",
    "            'drought': {'units': 'classification'},\n",
    "            'LST_Day_1km': {'units': 'degrees C'},\n",
    "            'NDVI': {'units': 'unitless'},\n",
    "            'ET': {'units': 'mm'},\n",
    "            'PET': {'units': 'mm'}}\n",
    "\n",
    "# Define land unit names\n",
    "if(in_fc_path == 'projects/dri-apps/assets/blm-admin/blm-natl-grazing-allotment-polygons-simplified-clean'):\n",
    "    land_unit_long = 'BLM_Natl_Grazing_Allotment_Polygons'\n",
    "    land_unit_short = 'BLM_Allotments'\n",
    "elif(in_fc_path == 'projects/dri-apps/assets/blm-admin/blm-natl-admu-statesoffice_polygons'):\n",
    "    land_unit_long = 'BLM_Natl_FieldOffice_Polygons'\n",
    "    land_unit_short = 'BLM_FieldOffices'\n",
    "elif(in_fc_path == 'projects/dri-apps/assets/blm-admin/blm-natl-admu-districtoffice_polygons'):\n",
    "    land_unit_long = 'BLM_Natl_DistrictOffice_Polygons'\n",
    "    land_unit_short = 'BLM_DistrictOffices'\n",
    "elif(in_fc_path == 'projects/dri-apps/assets/blm-admin/blm-natl-admu-fieldoffice_polygons'):\n",
    "    land_unit_long = 'BLM_Natl_StateOffice_Polygons'\n",
    "    land_unit_short = 'BLM_StateOffices'\n",
    "    \n",
    "# Pull out additional variables needed to run exports\n",
    "in_ic_paths = in_ic_dict.get(in_ic_name).get('in_ic_paths')\n",
    "in_ic_res = ee.ImageCollection(in_ic_paths[0]).first().projection().nominalScale().getInfo()\n",
    "var_type = in_ic_dict.get(in_ic_name).get('var_type')\n",
    "var_units = var_dict.get(var_name).get('units')\n",
    "out_path = f\"projects/dri-apps/assets/blm-database/{land_unit_short.replace('_', '').lower()}-{in_ic_name.replace('_', '').lower()}-{var_name.replace('_', '').lower()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20220104', '20220111', '20220118', '20220125']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b919c44e5f4a42b84fe42a69c4786c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Toggâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if in_ic_paths == ['projects/climate-engine/usdm/weekly']:\n",
    "\n",
    "    # Run function to pre-process the GridMET drought data\n",
    "    in_i = eedb_col.preprocess_usdm(in_ic_paths, var_name, start_date, end_date)\n",
    "\n",
    "    # Get list of date strings from image\n",
    "    in_dates = in_i.bandNames().getInfo()\n",
    "print(in_dates)\n",
    "\n",
    "vis = {\n",
    "'min': -4,\n",
    "'max': 4,\n",
    "'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5']}\n",
    "\n",
    "img = in_i.select([in_dates[0]])\n",
    "Map.addLayer(img, vis, 'usdm', True, 0.5)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create database image collection and append time-series images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"projects/dri-apps/assets/blm-database/blmallotments-lsndvi-ndvi\",\n",
      "  \"name\": \"projects/dri-apps/assets/blm-database/blmallotments-lsndvi-ndvi\",\n",
      "  \"type\": \"IMAGE_COLLECTION\",\n",
      "  \"updateTime\": \"2023-04-28T17:32:30.746081Z\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"projects/dri-apps/assets/blm-database/blmallotments-lsndvi-ndvi\",\n",
      "  \"name\": \"projects/dri-apps/assets/blm-database/blmallotments-lsndvi-ndvi\",\n",
      "  \"type\": \"IMAGE_COLLECTION\",\n",
      "  \"updateTime\": \"2023-04-28T17:32:30.746081Z\"\n",
      "}\n",
      "Appending to Image Collection for dates 2022-01-01 00:00:00 - 2022-07-01 00:00:00\n",
      "111319.49079327357\n",
      "Running 20220101\n",
      "Running 20220117\n",
      "Running 20220202\n",
      "Running 20220218\n",
      "Running 20220306\n",
      "Running 20220322\n",
      "Running 20220407\n",
      "Running 20220423\n",
      "Running 20220509\n",
      "Running 20220525\n",
      "Running 20220610\n",
      "Running 20220626\n"
     ]
    }
   ],
   "source": [
    "# If there is no Image Collection asset at the out_path create one and export ID image\n",
    "if os.system(f\"earthengine asset info {out_path}\") == 256:\n",
    "\n",
    "    print(\"Initializing Image Collection by creating EE asset and exporting ID image\")\n",
    "    \n",
    "    # Create dictionary of properties\n",
    "    properties = {'system:index': '0_id', 'land_unit_long': land_unit_long, 'land_unit_short': land_unit_short, 'in_fc_path': in_fc_path, 'in_fc_id': in_fc_id,\n",
    "                  'in_ic_paths': in_ic_paths[0], 'in_ic_name': in_ic_name, 'in_ic_res': in_ic_res, 'var_type': var_type, 'var_name': var_name', var_units': var_units}\n",
    "    \n",
    "    # Apply ID image function to input feature collection\n",
    "    out_list = eedb_cor.generate_id_img(in_fc = in_fc, in_fc_id = in_fc_id)\n",
    "    out_i = ee.Image(out_list.get(0))\n",
    "    out_fc = ee.FeatureCollection(out_list.get(1))\n",
    "    \n",
    "    # Generate empty Image Collection asset to append images\n",
    "    os.system(f\"earthengine create collection {out_path}\")\n",
    "    \n",
    "    # Export ID image to new Image Collection\n",
    "    task = ee.batch.Export.image.toAsset(\n",
    "        image = out_i.set(properties),\n",
    "        description = f\"initialize - {land_unit_short.replace('_', '').lower()} {in_ic_name.replace('_', '').lower()} {var_name.replace('_', '').lower()} - id\",\n",
    "        assetId = out_path + '/0_id',\n",
    "        region = out_fc.geometry().buffer(20),\n",
    "        scale = 22.264,\n",
    "        maxPixels = 1e13)\n",
    "    task.start()\n",
    "\n",
    "    \n",
    "# If there is an Image Collection asset at the out_path export time-series images\n",
    "elif os.system(f\"earthengine asset info {out_path}\") == 0:\n",
    "    \n",
    "    print(f\"Appending to Image Collection for dates {start_date} - {end_date}\")\n",
    "    \n",
    "    # ----- Preprocess input Image Collection based on path -----\n",
    "    \n",
    "    if in_ic_paths == ['GRIDMET/DROUGHT']:\n",
    "    \n",
    "        # Run function to pre-process the GridMET drought data\n",
    "        in_i = eedb_col.preprocess_gm_drought(in_ic_paths, var_name, start_date, end_date)\n",
    "        \n",
    "        # Get list of date strings from image\n",
    "        in_dates = in_i.bandNames().getInfo()\n",
    "        \n",
    "    elif in_ic_paths == ['IDAHO_EPSCOR/GRIDMET']:\n",
    "    \n",
    "        # Run function to pre-process the GridMET drought data\n",
    "        in_i = eedb_col.preprocess_gm(in_ic_paths, var_name, start_date, end_date)\n",
    "    \n",
    "        # Get list of date strings from image\n",
    "        in_dates = in_i.bandNames().getInfo()\n",
    "    \n",
    "    elif in_ic_paths == ['projects/rap-data-365417/assets/vegetation-cover-v3'] or in_ic_paths == ['projects/rap-data-365417/assets/npp-partitioned-v3'] or in_ic_paths == ['projects/rap-data-365417/assets/npp-partitioned-16day-v3']:\n",
    "    \n",
    "        # Run function to pre-process the GridMET drought data\n",
    "        in_i = eedb_col.preprocess_rap(in_ic_paths, var_name, start_date, end_date)\n",
    "    \n",
    "        # Get list of date strings from image\n",
    "        in_dates = in_i.bandNames().getInfo()\n",
    "\n",
    "    elif in_ic_paths == ['projects/climate-engine/usdm/weekly']:\n",
    "    \n",
    "        # Run function to pre-process the GridMET drought data\n",
    "        in_i = eedb_col.preprocess_usdm(in_ic_paths, var_name, start_date, end_date)\n",
    "    \n",
    "        # Get list of date strings from image\n",
    "        in_dates = in_i.bandNames().getInfo()\n",
    "\n",
    "    elif in_ic_paths == ['MODIS/061/MOD11A2']:\n",
    "    \n",
    "        # Run function to pre-process the GridMET drought data\n",
    "        in_i = eedb_col.preprocess_modlst(in_ic_paths, var_name, start_date, end_date)\n",
    "        \n",
    "        # Get list of date strings from image\n",
    "        in_dates = in_i.bandNames().getInfo()\n",
    "    \n",
    "    elif in_ic_paths == ['LANDSAT/LT05/C02/T1_L2', 'LANDSAT/LE07/C02/T1_L2', 'LANDSAT/LC08/C02/T1_L2', 'LANDSAT/LC09/C02/T1_L2']:\n",
    "    \n",
    "        # Run function to pre-process the Landsat SR NDVI data\n",
    "        in_i = eedb_col.preprocess_lsndvi(in_ic_paths, var_name, start_date, end_date)\n",
    "        print(in_i.projection().nominalScale().getInfo())\n",
    "    \n",
    "        # Get list of date strings from image\n",
    "        in_dates = in_i.bandNames().getInfo()\n",
    "        \n",
    "    elif in_ic_paths == ['MODIS/061/MOD16A2']:\n",
    "    \n",
    "        # Run function to pre-process the GridMET drought data\n",
    "        in_i = eedb_col.preprocess_modet(in_ic_paths, var_name, start_date, end_date)\n",
    "        \n",
    "        # Get list of date strings from image\n",
    "        in_dates = in_i.bandNames().getInfo()\n",
    "\n",
    "\n",
    "    # ---------------------------- Iterate over in_dates with functions ---------------------------------\n",
    "        \n",
    "    for in_date in in_dates:\n",
    "    \n",
    "        print('Running ' + in_date)\n",
    "    \n",
    "        # Select date band for single date\n",
    "        in_i_date = in_i.select([in_date])\n",
    "    \n",
    "        # Create dictionary of properties        \n",
    "        properties = {'system:index': in_date, 'land_unit_long': land_unit_long, 'land_unit_short': land_unit_short, 'in_fc_path': in_fc_path,\\\n",
    "                      'in_fc_id': in_fc_id, 'in_ic_paths': in_ic_paths[0], 'in_ic_name': in_ic_name, 'in_ic_res': in_ic_res, 'var_type': var_type,\\\n",
    "                      'var_name': var_name, var_units': var_units}\n",
    "\n",
    "        if var_type == 'Continuous':\n",
    "        \n",
    "            # Run function to get time-series statistics for input feature collection\n",
    "            out_fc = eedb_cor.img_to_pts_continuous(in_i_date, in_fc)\n",
    "\n",
    "            # Convert centroid time-series to image collection time-series\n",
    "            out_i = eedb_cor.pts_to_img_continuous(in_fc = out_fc)\n",
    "        \n",
    "        elif var_type == 'Categorical':\n",
    "        \n",
    "            # Run function to get time-series statistics for input feature collection for continuous variables\n",
    "            out_fc = eedb_cor.img_to_pts_categorical(in_i_date, in_fc, in_ic_name = in_ic_name)\n",
    "       \n",
    "            # Convert centroid time-series to image collection time-series\n",
    "            out_i = eedb_cor.pts_to_img_categorical(in_fc = out_fc, in_ic_name = in_ic_name)\n",
    "        \n",
    "        # Create out region for export\n",
    "        out_region = out_fc.geometry().buffer(20)\n",
    "        \n",
    "        # Export the image\n",
    "        eedb_cor.export_img(out_i = out_i, out_region = out_region, out_path = out_path, out_id = in_date, properties = properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Export_BLM_TimeSeries_ImageCollection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
